{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CUSTOM NORMALIZER:\n",
      "[[ 1.   1.  -1.   1.   1.   1.   0.1  1.   1.   0.   1.  -1.  -0.6  1. ]\n",
      " [-0.1 -0.3  1.   0.3 -0.3 -0.4  0.7 -0.2 -0.5  0.3 -0.4  1.   1.   0.2]\n",
      " [ 0.1 -0.3  1.  -1.  -0.1 -0.3  0.9 -0.5 -0.5  0.3 -0.8  1.   0.1 -1. ]\n",
      " [ 0.2  0.3  1.  -1.  -0.   0.1  1.  -0.5  0.1  1.  -0.4  1.   0.1 -1. ]\n",
      " [-1.  -1.  -1.  -0.2 -1.  -1.  -1.  -1.  -1.  -1.  -1.  -1.  -1.  -0.3]]\n",
      "TF NORMALIZER:\n",
      "[[ 1.5  1.6 -1.2  1.5  1.7  1.7 -0.4  1.8  1.7 -0.2  1.9 -1.2 -0.7  1.6]\n",
      " [-0.2 -0.4  0.8  0.7 -0.3 -0.4  0.5  0.1 -0.5  0.3 -0.1  0.8  1.6  0.6]\n",
      " [ 0.1 -0.4  0.8 -1.1 -0.1 -0.3  0.8 -0.4 -0.5  0.3 -0.7  0.8  0.3 -1. ]\n",
      " [ 0.2  0.6  0.8 -1.1  0.1  0.3  0.9 -0.3  0.5  1.3 -0.1  0.8  0.3 -1. ]\n",
      " [-1.6 -1.4 -1.2 -0.  -1.4 -1.3 -1.8 -1.1 -1.2 -1.7 -1.  -1.2 -1.3 -0.1]]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from matplotlib import pyplot as plt\n",
    "from copy import deepcopy\n",
    "\n",
    "class Normalizer:\n",
    "    \"\"\"\n",
    "    The Great Normalizer\n",
    "    \"\"\"\n",
    "    mins: np.ndarray\n",
    "    maxs: np.ndarray\n",
    "    span: np.ndarray\n",
    "    mids: np.ndarray\n",
    "\n",
    "    def __init__(self, reference_inputs: np.ndarray):\n",
    "        self.mins = np.min(reference_inputs, 0)\n",
    "        self.maxs = np.max(reference_inputs, 0)\n",
    "        self.span = self.maxs - self.mins\n",
    "        # mids = span / 2 + mins\n",
    "        # and thus:\n",
    "        # mids = (maxs + mins) / 2\n",
    "        self.mids = (self.maxs + self.mins) / 2\n",
    "\n",
    "    def scale(self, set: np.ndarray):\n",
    "        # k0 = (reference_inputs[0] - mids) / (span / 2)\n",
    "        # and thus:\n",
    "        # k0 = 2*(reference_inputs[0] - mids) / span\n",
    "        return 2 * np.subtract(set, self.mids) / self.span\n",
    "\n",
    "\n",
    "def sig(x):\n",
    "    return 1 / (1 + np.exp(-x))\n",
    "\n",
    "def shp(x):\n",
    "    return x.reshape(len(x), -1)\n",
    "def ytransform(y):\n",
    "    arr = np.zeros((len(y), 10))\n",
    "    rng = np.array([np.arange(0, len(y)), y]).T\n",
    "    for i, v in rng:\n",
    "        arr[i,v] = 1\n",
    "    return arr\n",
    "\n",
    "\n",
    "def polynom(inputs: np.ndarray, degree=2):\n",
    "    if degree < 2:\n",
    "        raise Exception(\"Degree should be at least 2\")\n",
    "\n",
    "    transposed = inputs.T\n",
    "    base = len(transposed)\n",
    "\n",
    "    pols = []\n",
    "    newgen = []\n",
    "    for i in range(base):\n",
    "        newgen.append([i])\n",
    "    pols.extend(newgen)\n",
    "\n",
    "    for deg in range(1, degree):\n",
    "        lastgen = newgen\n",
    "        newgen = []\n",
    "        for p in lastgen:\n",
    "            for i in range(p[-1], base):\n",
    "                pnext = [*p, i]\n",
    "                pnext.sort()\n",
    "                newgen.append(pnext)\n",
    "        pols.extend(newgen)\n",
    "\n",
    "    new_inputs = []\n",
    "    for p in pols:\n",
    "        new_inputs.append(deepcopy(transposed[p[0]]))\n",
    "        for i in p[1:]:\n",
    "            new_inputs[-1] *= transposed[i]\n",
    "    return np.array(new_inputs).T\n",
    "\n",
    "dataset = np.array([\n",
    "    [2104, 5, 1, 45, 460],\n",
    "    [1416, 3, 2, 40, 232],\n",
    "    [1534, 3, 2, 30, 315],\n",
    "    [1600, 4, 2, 30, 389],\n",
    "    [852, 2, 1, 36, 178],\n",
    "])\n",
    "x_train = polynom(dataset[:, :-1])\n",
    "\n",
    "normer = Normalizer(x_train)\n",
    "x_train1 = normer.scale(x_train)\n",
    "\n",
    "norm_l = tf.keras.layers.Normalization(axis=-1)\n",
    "norm_l.adapt(x_train)\n",
    "x_train2 = np.array(norm_l(x_train))\n",
    "\n",
    "y_train = dataset[:, -1:]\n",
    "\n",
    "np.set_printoptions(precision=1, suppress=True)\n",
    "print(\"CUSTOM NORMALIZER:\")\n",
    "print(x_train1)\n",
    "print(\"TF NORMALIZER:\")\n",
    "print(x_train2)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.8 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "c19fa61d258bb2b35aae2ada233c33e2817c1ce895aa48acba720c6bf7cbe3cb"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
