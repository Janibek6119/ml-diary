{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import typing\n",
    "\n",
    "\n",
    "def sig(x):\n",
    "    return 1 / (1 + np.exp(-x))\n",
    "\n",
    "def err_gradient(errors, values):\n",
    "    return errors * values * (1 - values)\n",
    "\n",
    "\n",
    "def create_weights(neurons: typing.Iterable[int]):\n",
    "    if len(neurons) < 2:\n",
    "        raise Exception(\"At least two values (input layer & output layer) are required\")\n",
    "    for size in neurons:\n",
    "        if size < 1:\n",
    "            raise Exception(\"Minimum 1 neuron per layer\")\n",
    "    weights: list[np.ndarray[typing.Any, np.dtype[np.float64]]] = []\n",
    "    for i in range(0, len(neurons)-1):\n",
    "        weights.append(2 * np.random.random((neurons[i], neurons[i+1])) - 1)\n",
    "    return weights\n",
    "\n",
    "\n",
    "training_data = np.array([\n",
    "    [0, 0, 0, 0],\n",
    "    [0, 0, 1, 0],\n",
    "    [0, 1, 0, 0],\n",
    "    [0, 1, 1, 0],\n",
    "    [1, 0, 0, 1],\n",
    "    [1, 0, 1, 1],\n",
    "    [1, 1, 0, 1],\n",
    "    [1, 1, 1, 1]\n",
    "])\n",
    "# [cases, inputs]\n",
    "training_inputs = training_data[:, 0:3]\n",
    "# [cases, outputs]\n",
    "training_outputs = training_data[:, 3:]\n",
    "\n",
    "np.random.seed(1)\n",
    "\n",
    "weights = create_weights([3,5,6,7,1])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.00344464]\n",
      " [0.00213525]\n",
      " [0.00197481]\n",
      " [0.00144891]\n",
      " [0.99790384]\n",
      " [0.99760688]\n",
      " [0.99781509]\n",
      " [0.99743688]]\n"
     ]
    }
   ],
   "source": [
    "for i in range(10000):\n",
    "    values = [sig(np.dot(training_inputs, weights[0]))]\n",
    "    for w in weights[1:]:\n",
    "        values.append(sig(np.dot(values[-1], w)))\n",
    "\n",
    "    gradients = [err_gradient(training_outputs - values[-1], values[-1])] # reversed order, output to input\n",
    "    for i in range(len(weights)-1, 0, -1):\n",
    "        gradients.append(err_gradient(np.dot(gradients[-1], weights[i].T), values[i-1]))\n",
    "    gradients.reverse() # straight order, input to output\n",
    "\n",
    "    for i in range(len(weights)-1, 0, -1):\n",
    "        weights[i] += np.dot(values[i-1].T, gradients[i])\n",
    "    weights[0] += np.dot(training_inputs.T, gradients[0])\n",
    "\n",
    "A_VALS = values[-1]\n",
    "np.set_printoptions(precision=8, suppress=True)\n",
    "print(A_VALS)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.8 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "c19fa61d258bb2b35aae2ada233c33e2817c1ce895aa48acba720c6bf7cbe3cb"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
