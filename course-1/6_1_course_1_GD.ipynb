{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "20625.0\n",
      "(-42500.0, -200.0)\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "dataset = np.array([\n",
    "    [100, 150],\n",
    "    [150, 175],\n",
    "    [200, 200],\n",
    "    [250, 225],\n",
    "    [300, 250]\n",
    "])\n",
    "\n",
    "w = 0\n",
    "b = 0\n",
    "alpha = 0.000_01\n",
    "\n",
    "def cost():\n",
    "    sum_sqr_err = 0\n",
    "    for entry in dataset:\n",
    "        y = w*entry[0] + b\n",
    "        err = y - entry[1]\n",
    "        sum_sqr_err += err ** 2\n",
    "    return sum_sqr_err / (len(dataset) * 2)\n",
    "\n",
    "\n",
    "def gradients():\n",
    "    sum_err_dw = 0\n",
    "    sum_err_db = 0\n",
    "    for entry in dataset:\n",
    "        y = w*entry[0] + b\n",
    "        err = y - entry[1]\n",
    "        sum_err_dw += err * entry[0]  # Since J is ((wx+b-y)^2)/2, dJ/dw = x*(wx+b-y) = x*err\n",
    "        sum_err_db += err             # Since J is ((wx+b-y)^2)/2, dJ/db = (wx+b-y) = err\n",
    "    gradient_w = sum_err_dw / len(dataset)\n",
    "    gradient_b = sum_err_db / len(dataset)\n",
    "    return gradient_w, gradient_b\n",
    "\n",
    "print(cost())\n",
    "print(gradients())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration    0: Cost 6.63e+03  dj_dw: -4.250e+04, dj_db: -2.000e+02   w:  4.250e-01, b: 2.00000e-03\n",
      "Iteration 1000: Cost 5.54e+02  dj_dw:  4.932e-02, dj_db: -1.110e+01   w:  9.439e-01, b: 1.15351e-01\n",
      "Iteration 2000: Cost 5.53e+02  dj_dw:  4.927e-02, dj_db: -1.109e+01   w:  9.434e-01, b: 2.26270e-01\n",
      "Iteration 3000: Cost 5.52e+02  dj_dw:  4.922e-02, dj_db: -1.107e+01   w:  9.429e-01, b: 3.37066e-01\n",
      "Iteration 4000: Cost 5.51e+02  dj_dw:  4.916e-02, dj_db: -1.106e+01   w:  9.425e-01, b: 4.47739e-01\n",
      "Iteration 5000: Cost 5.49e+02  dj_dw:  4.911e-02, dj_db: -1.105e+01   w:  9.420e-01, b: 5.58289e-01\n",
      "Iteration 6000: Cost 5.48e+02  dj_dw:  4.905e-02, dj_db: -1.104e+01   w:  9.415e-01, b: 6.68717e-01\n",
      "Iteration 7000: Cost 5.47e+02  dj_dw:  4.900e-02, dj_db: -1.102e+01   w:  9.410e-01, b: 7.79021e-01\n",
      "Iteration 8000: Cost 5.46e+02  dj_dw:  4.894e-02, dj_db: -1.101e+01   w:  9.405e-01, b: 8.89203e-01\n",
      "Iteration 9000: Cost 5.45e+02  dj_dw:  4.889e-02, dj_db: -1.100e+01   w:  9.400e-01, b: 9.99263e-01\n",
      "Iteration 9999: Cost 5.43e+02  dj_dw:  4.883e-02, dj_db: -1.099e+01   w:  9.395e-01, b: 1.10909e+00\n",
      "543.3006595274906\n",
      "(0.0488341727090301, -10.987661730365144)\n"
     ]
    }
   ],
   "source": [
    "import math\n",
    "for i in range(10000):\n",
    "  gw,gb = gradients()\n",
    "  # print((gw,gb))\n",
    "  w -= alpha*gw\n",
    "  b -= alpha*gb\n",
    "  if i % 1000 == 0 or i == 9999:\n",
    "      print(f\"Iteration {i:4}: Cost {cost():0.2e} \",\n",
    "            f\"dj_dw: {gw: 0.3e}, dj_db: {gb: 0.3e}  \",\n",
    "            f\"w: {w: 0.3e}, b:{b: 0.5e}\")\n",
    "print(cost())\n",
    "print(gradients())\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.11.0 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "c261aea317cc0286b3b3261fbba9abdec21eaa57589985bb7a274bf54d6cc0a7"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
